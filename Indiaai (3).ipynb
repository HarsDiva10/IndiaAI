{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVuFOR_fy8q7",
        "outputId": "acee09b7-72ad-4987-d26a-57d300cb5b5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                      precision    recall  f1-score   support\n",
            "\n",
            "                               Any Other Cyber Crime       0.43      0.23      0.30      3670\n",
            "Child Pornography CPChild Sexual Abuse Material CSAM       0.65      0.25      0.36       123\n",
            "                      Crime Against Women & Children       0.00      0.00      0.00         4\n",
            "                                Cryptocurrency Crime       0.68      0.44      0.53       166\n",
            "                      Cyber Attack/ Dependent Crimes       1.00      1.00      1.00      1261\n",
            "                                     Cyber Terrorism       0.00      0.00      0.00        52\n",
            "      Hacking  Damage to computercomputer system etc       0.42      0.22      0.29       592\n",
            "                            Online Cyber Trafficking       0.00      0.00      0.00        61\n",
            "                              Online Financial Fraud       0.81      0.95      0.87     18896\n",
            "                            Online Gambling  Betting       0.71      0.04      0.07       134\n",
            "               Online and Social Media Related Crime       0.55      0.59      0.57      4139\n",
            "                                          Ransomware       0.33      0.06      0.10        18\n",
            "           RapeGang Rape RGRSexually Abusive Content       1.00      0.91      0.95       912\n",
            "                               Sexually Explicit Act       0.30      0.02      0.04       535\n",
            "                           Sexually Obscene material       0.47      0.12      0.19       666\n",
            "\n",
            "                                            accuracy                           0.76     31229\n",
            "                                           macro avg       0.49      0.32      0.35     31229\n",
            "                                        weighted avg       0.72      0.76      0.72     31229\n",
            "\n",
            "'id' column not found. Available columns: ['category', 'sub_category', 'crimeaditionalinfo', 'processed_text', 'predicted_category']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download necessary resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Load Data\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/test.csv')\n",
        "\n",
        "# Use 'crimeaditionalinfo' column instead of 'description'\n",
        "description_column = 'crimeaditionalinfo'\n",
        "\n",
        "# Preprocessing Function\n",
        "def preprocess_text(text):\n",
        "    # Check if text is a string, if not, convert to string\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text.lower())  # Lowercase & Remove punctuation\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    return ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
        "\n",
        "# Apply preprocessing\n",
        "train_data['processed_text'] = train_data[description_column].apply(preprocess_text)\n",
        "test_data['processed_text'] = test_data[description_column].apply(preprocess_text)\n",
        "\n",
        "# Combine train and test data to fit LabelEncoder on all categories\n",
        "all_categories = pd.concat([train_data['category'], test_data['category']])\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(all_categories)\n",
        "\n",
        "# Encode Labels\n",
        "y_train = label_encoder.transform(train_data['category'])\n",
        "y_test = label_encoder.transform(test_data['category'])\n",
        "\n",
        "# Vectorization and Model Pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(max_features=5000)),\n",
        "    ('classifier', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "# Train Model\n",
        "pipeline.fit(train_data['processed_text'], y_train)\n",
        "\n",
        "# Predict and Evaluate\n",
        "y_pred = pipeline.predict(test_data['processed_text'])\n",
        "\n",
        "# Get unique labels in predictions and true values\n",
        "unique_labels = sorted(set(y_test) | set(y_pred))\n",
        "\n",
        "# Filter target names to match unique labels\n",
        "target_names = [label_encoder.classes_[i] for i in unique_labels]\n",
        "\n",
        "# Generate classification report with filtered target names\n",
        "print(classification_report(y_test, y_pred, target_names=target_names, labels=unique_labels))\n",
        "\n",
        "# Save Predictions\n",
        "test_data['predicted_category'] = label_encoder.inverse_transform(y_pred)\n",
        "\n",
        "# Check if 'id' column exists, if not, print available columns\n",
        "if 'id' not in test_data.columns:\n",
        "    print(f\"'id' column not found. Available columns: {test_data.columns.tolist()}\")\n",
        "    # If 'id' is not present, you can use the index as 'id'\n",
        "    test_data['id'] = test_data.index  # Assign index to 'id' column\n",
        "\n",
        "# Now save the predictions with 'id'\n",
        "test_data[['id', 'predicted_category']].to_csv('/content/predictions.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9BWqrJD4xI8",
        "outputId": "b270856f-2c29-4d33-841b-99dff3a736a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Optional\n",
        "import joblib\n",
        "import re\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# Load pre-trained model and label encoder\n",
        "model = joblib.load('crime_classifier_model.pkl')  # Replace with actual model path\n",
        "label_encoder = joblib.load('label_encoder.pkl')\n",
        "\n",
        "# Define Request Schema\n",
        "class ReportRequest(BaseModel):\n",
        "    description: str\n",
        "\n",
        "# Endpoint for Classifying Report\n",
        "@app.post(\"/classify/\")\n",
        "def classify_report(report: ReportRequest):\n",
        "    # Preprocess the text (this should match the training pre-processing)\n",
        "    processed_text = preprocess_text(report.description)\n",
        "    category_pred = model.predict([processed_text])\n",
        "    category_name = label_encoder.inverse_transform(category_pred)[0]\n",
        "\n",
        "    return {\"description\": report.description, \"predicted_category\": category_name}\n",
        "\n",
        "# Helper function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
        "    return text\n",
        "\n",
        "# Run the app: uvicorn main:app --reload"
      ],
      "metadata": {
        "id": "fqdBvXtzzFlM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}